{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tree import Tree\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"This Washington paper describes the psychosocial effects of a program of Supported Employment (SE) for persons with severe mental illness the SE program involves extended individualized supported employment for clients through a mobile job support worker and jsw who maintains contact with the client after job placement and supports the client in a variety of ways a 50% simple random sample was taken of all persons who entered the thresholds agency between March 1st 93 and February 28th 95 and who met study criteria the resulting 484 cases were randomly assigned to either the SE condition treatment group or the usual protocol control group which consisted of life skills training and employment in an in-house sheltered workshop setting all participants were measured at intake and at three months after beginning employment on two measures of psychological Funk turning the bprs and gas and two measures of self-esteem are Sensa significant treatment effects were found on all four measures but they were in the opposite direction from what was hypothesized instead of functioning better and having more self-esteem persons in SE had lower-functioning levels and lower self-esteem the most likely explanation is that people who work in low-paying service jobs in real-world settings generally do not like them and experienced significant job stress whether they have severe mental illness or not the implications for theory in psychosocial Rehabilitation are considered.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering stop words\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "words = word_tokenize(txt, language=\"english\")\n",
    "filtered_words = [w for w in words if w.casefold() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "filtered_lematized_words = [lemmatizer.lemmatize(w) for w in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_tags = pos_tag(filtered_lematized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all named entities\n",
    "tree = ne_chunk(words_with_tags, binary=True)\n",
    "named_entities = []\n",
    "current_chunk = []\n",
    "\n",
    "for i in tree:\n",
    "    if type(i) == Tree:           \n",
    "        current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "        if current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)                  \n",
    "            if named_entity not in named_entities:\n",
    "                named_entities.append(named_entity)\n",
    "                current_chunk = []\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all words that have over 3 occurrences\n",
    "FREQ_THRESHOLD = 3\n",
    "frequency_distribution = FreqDist(filtered_lematized_words)\n",
    "most_common = [x[0] for x in frequency_distribution.most_common(20) if x[1] >= FREQ_THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all proper nouns\n",
    "prop_nouns = [x[0] for x in words_with_tags if x[1] == \"NNP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Washington']\n",
      "['SE', 'job', 'person', 'employment', 'client', 'measure', 'self-esteem']\n",
      "['Washington', 'Employment', 'SE', 'SE', 'March', 'February', 'SE', 'Funk', 'Sensa', 'SE', 'Rehabilitation']\n"
     ]
    }
   ],
   "source": [
    "print(named_entities)\n",
    "print(most_common)\n",
    "print(prop_nouns)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b55fb9c3b2ae460387b9f24a585a06d07a1c685c2da458447f8c89d29042cf89"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
